{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PyTorch Training Pipeline Using Dataset & DataLoader**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Import Required Libraries**\n",
    "Import all necessary libraries for data manipulation, preprocessing, and PyTorch utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gaa7OgL-TdPa"
   },
   "outputs": [],
   "source": [
    "# Import numpy for numerical operations\n",
    "import numpy as np\n",
    "# Import pandas for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Import torch for tensor operations and neural networks\n",
    "import torch\n",
    "\n",
    "# Import train_test_split for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import StandardScaler for feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import LabelEncoder for encoding categorical labels\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Load and Inspect Dataset**\n",
    "Load the breast cancer dataset from a remote CSV file and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "35b3pUI1Turc",
    "outputId": "14f80228-0e9f-4e7e-b44a-f629e63525fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the breast cancer dataset from a remote CSV file\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTASXrxUTyeW",
    "outputId": "78c4463b-f939-4e4b-c5e5-0e7ae30d88b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the shape of the DataFrame (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Data Cleaning**\n",
    "Remove unnecessary columns (`id`, `Unnamed: 32`) to keep only relevant features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VMgbJGUOT_SX"
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns: 'id' and 'Unnamed: 32'\n",
    "df.drop(columns=['id', 'Unnamed: 32'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "43Yhb8eVUXeE",
    "outputId": "b0608336-73f7-4c8b-f2a8-4c061ff75ace"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows after dropping columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1G7UWSTSM4M"
   },
   "source": [
    "## **4. Train-Test Split**\n",
    "Split the dataset into training and testing sets for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rMX3fS-xUjDp"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:, 1:],  # Features (all columns except first)\n",
    "    df.iloc[:, 0],   # Labels (first column)\n",
    "    test_size=0.2    # 20% for testing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b4HNCjlSRwF"
   },
   "source": [
    "## **5. Feature Scaling**\n",
    "Standardize the features using `StandardScaler` to improve model convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9U6kQsjTU5ZE"
   },
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data and transform\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data using the same scaler\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMmrSA88VMZQ",
    "outputId": "cf2c0be9-c3a8-4559-9545-0728a5aee39c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.27203462, -0.55046419, -1.2344535 , ..., -0.48470413,\n",
       "         0.17803342,  0.8415128 ],\n",
       "       [ 1.5184503 , -0.25170149,  1.56390743, ...,  1.70130269,\n",
       "         1.27399793,  0.50436955],\n",
       "       [-1.23402321, -0.03048026, -1.22270249, ..., -1.02259891,\n",
       "         0.532854  , -0.17551733],\n",
       "       ...,\n",
       "       [-1.54817636, -1.70218299, -1.53025475, ..., -1.04849585,\n",
       "         0.57264697,  0.39404194],\n",
       "       [-0.52745811, -0.30415601, -0.55492102, ..., -0.26960715,\n",
       "         0.96228639, -0.79884032],\n",
       "       [ 0.84766066,  0.64230597,  0.78996168, ...,  1.30066172,\n",
       "         0.5660148 , -0.42137429]], shape=(455, 30))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the scaled training features\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "uYoHEPdsVX3P",
    "outputId": "63f0c821-e613-472f-8399-a4755410e5c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341    B\n",
       "162    M\n",
       "424    B\n",
       "96     B\n",
       "70     M\n",
       "      ..\n",
       "312    B\n",
       "557    B\n",
       "59     B\n",
       "409    B\n",
       "264    M\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the training labels\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XhX--USSU5q"
   },
   "source": [
    "## **6. Label Encoding**\n",
    "Convert categorical labels to numeric values using `LabelEncoder` for compatibility with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xleQoeKbVafX"
   },
   "outputs": [],
   "source": [
    "# Initialize label encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoder on training labels and transform\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform test labels using the same encoder\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHQJ5QegVtdF",
    "outputId": "8f9aa10e-41a5-42d9-dba6-b17fda2e8d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the encoded training labels\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZ4_HRZcSZwa"
   },
   "source": [
    "## **7. Convert Numpy Arrays to PyTorch Tensors**\n",
    "Transform the processed numpy arrays into PyTorch tensors for model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CHvyHOq9VuTE"
   },
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors (float32 type)\n",
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KRGQrGrWWQNN",
    "outputId": "9429f359-6f31-4d49-ca15-21a0b6059123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of the training feature tensor\n",
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXkt8Mq_WR_I",
    "outputId": "cdfbdf33-0200-48da-973c-0a3b25132a8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of the training label tensor\n",
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch Dataset and DataLoader classes\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Custom Dataset Class**\n",
    "Define a custom PyTorch `Dataset` class to handle feature and label access for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hZNrc4trikf4"
   },
   "outputs": [],
   "source": [
    "# Define a custom Dataset class for features and labels\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, features, labels):\n",
    "        # Store features and labels\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return number of samples\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return feature and label at given index\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Create Dataset Instances**\n",
    "Instantiate training and testing datasets using the custom Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4vrso69IjqL-"
   },
   "outputs": [],
   "source": [
    "# Create training dataset instance\n",
    "train_dataset = CustomDataset(\n",
    "    X_train_tensor,\n",
    "    y_train_tensor\n",
    ")\n",
    "\n",
    "# Create testing dataset instance\n",
    "test_dataset = CustomDataset(\n",
    "    X_test_tensor,\n",
    "    y_test_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. DataLoader for Batching**\n",
    "Wrap the datasets with PyTorch `DataLoader` to enable efficient batching and shuffling during training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SqTKvWm9w3pZ"
   },
   "outputs": [],
   "source": [
    "# Create DataLoader for training data\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Create DataLoader for testing data\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Define the Neural Network Model**\n",
    "Create a simple feedforward neural network using PyTorch's `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch neural network module\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tNrloSpuSkwk"
   },
   "outputs": [],
   "source": [
    "# Define a simple neural network class\n",
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        # Call parent constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear layer: input features to 1 output\n",
    "        self.linear = nn.Linear(num_features, 1)\n",
    "        # Sigmoid activation for output\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features):\n",
    "        # Pass input through linear layer\n",
    "        out = self.linear(features)\n",
    "        # Apply sigmoid activation\n",
    "        out = self.sigmoid(out)\n",
    "        # Return output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gn_QAecdLJF"
   },
   "source": [
    "## **12. Set Training Hyperparameters**\n",
    "Specify the learning rate and number of epochs for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xkfjyefSXHcv"
   },
   "outputs": [],
   "source": [
    "# Set learning rate for optimizer\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Set number of epochs for training\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **13. Model, Optimizer, and Loss Function**\n",
    "Instantiate the model, optimizer (SGD), and binary cross-entropy loss function for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aDQUF7BZqenx"
   },
   "outputs": [],
   "source": [
    "# Create model instance with number of features as input size\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "# Define SGD optimizer with model parameters and learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define binary cross entropy loss function\n",
    "loss_function = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **14. Training Loop**\n",
    "Iterate over epochs and batches, performing forward and backward passes, updating model parameters, and printing the loss for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GxPsNM2_XQev",
    "outputId": "ee88b94b-06be-4601-a86a-822ada929d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.1602795422077179\n",
      "Epoch: 2, Loss: 0.04105423018336296\n",
      "Epoch: 3, Loss: 0.15081845223903656\n",
      "Epoch: 4, Loss: 0.1370118111371994\n",
      "Epoch: 5, Loss: 0.06466248631477356\n",
      "Epoch: 6, Loss: 0.1230577602982521\n",
      "Epoch: 4, Loss: 0.1370118111371994\n",
      "Epoch: 5, Loss: 0.06466248631477356\n",
      "Epoch: 6, Loss: 0.1230577602982521\n",
      "Epoch: 7, Loss: 0.13350827991962433\n",
      "Epoch: 8, Loss: 0.11811214685440063\n",
      "Epoch: 9, Loss: 0.022221488878130913\n",
      "Epoch: 10, Loss: 0.020276715978980064\n",
      "Epoch: 7, Loss: 0.13350827991962433\n",
      "Epoch: 8, Loss: 0.11811214685440063\n",
      "Epoch: 9, Loss: 0.022221488878130913\n",
      "Epoch: 10, Loss: 0.020276715978980064\n",
      "Epoch: 11, Loss: 0.02984280325472355\n",
      "Epoch: 12, Loss: 0.0352652445435524\n",
      "Epoch: 13, Loss: 0.028315788134932518\n",
      "Epoch: 11, Loss: 0.02984280325472355\n",
      "Epoch: 12, Loss: 0.0352652445435524\n",
      "Epoch: 13, Loss: 0.028315788134932518\n",
      "Epoch: 14, Loss: 0.017749732360243797\n",
      "Epoch: 15, Loss: 0.09125881642103195\n",
      "Epoch: 16, Loss: 0.08134667575359344\n",
      "Epoch: 17, Loss: 0.05789788439869881\n",
      "Epoch: 14, Loss: 0.017749732360243797\n",
      "Epoch: 15, Loss: 0.09125881642103195\n",
      "Epoch: 16, Loss: 0.08134667575359344\n",
      "Epoch: 17, Loss: 0.05789788439869881\n",
      "Epoch: 18, Loss: 0.18793728947639465\n",
      "Epoch: 19, Loss: 0.009118356741964817\n",
      "Epoch: 20, Loss: 0.018914779648184776\n",
      "Epoch: 21, Loss: 0.051994651556015015\n",
      "Epoch: 18, Loss: 0.18793728947639465\n",
      "Epoch: 19, Loss: 0.009118356741964817\n",
      "Epoch: 20, Loss: 0.018914779648184776\n",
      "Epoch: 21, Loss: 0.051994651556015015\n",
      "Epoch: 22, Loss: 0.176040381193161\n",
      "Epoch: 23, Loss: 0.07437866926193237\n",
      "Epoch: 24, Loss: 0.028338925912976265\n",
      "Epoch: 25, Loss: 0.06423287093639374\n",
      "Epoch: 26, Loss: 0.1303478628396988\n",
      "Epoch: 22, Loss: 0.176040381193161\n",
      "Epoch: 23, Loss: 0.07437866926193237\n",
      "Epoch: 24, Loss: 0.028338925912976265\n",
      "Epoch: 25, Loss: 0.06423287093639374\n",
      "Epoch: 26, Loss: 0.1303478628396988\n",
      "Epoch: 27, Loss: 0.008421763777732849\n",
      "Epoch: 28, Loss: 0.05550968647003174\n",
      "Epoch: 29, Loss: 0.03302476555109024\n",
      "Epoch: 30, Loss: 0.007675192318856716\n",
      "Epoch: 27, Loss: 0.008421763777732849\n",
      "Epoch: 28, Loss: 0.05550968647003174\n",
      "Epoch: 29, Loss: 0.03302476555109024\n",
      "Epoch: 30, Loss: 0.007675192318856716\n",
      "Epoch: 31, Loss: 0.003258917247876525\n",
      "Epoch: 32, Loss: 0.07155106961727142\n",
      "Epoch: 33, Loss: 0.038608405739068985\n",
      "Epoch: 34, Loss: 0.1299935132265091\n",
      "Epoch: 35, Loss: 0.010476278141140938\n",
      "Epoch: 31, Loss: 0.003258917247876525\n",
      "Epoch: 32, Loss: 0.07155106961727142\n",
      "Epoch: 33, Loss: 0.038608405739068985\n",
      "Epoch: 34, Loss: 0.1299935132265091\n",
      "Epoch: 35, Loss: 0.010476278141140938\n",
      "Epoch: 36, Loss: 0.009013001807034016\n",
      "Epoch: 37, Loss: 0.04207919165492058\n",
      "Epoch: 38, Loss: 0.016180356964468956\n",
      "Epoch: 39, Loss: 0.019410785287618637\n",
      "Epoch: 40, Loss: 0.0849883109331131\n",
      "Epoch: 36, Loss: 0.009013001807034016\n",
      "Epoch: 37, Loss: 0.04207919165492058\n",
      "Epoch: 38, Loss: 0.016180356964468956\n",
      "Epoch: 39, Loss: 0.019410785287618637\n",
      "Epoch: 40, Loss: 0.0849883109331131\n",
      "Epoch: 41, Loss: 0.005071624647825956\n",
      "Epoch: 42, Loss: 0.0007323073223233223\n",
      "Epoch: 43, Loss: 0.024253185838460922\n",
      "Epoch: 44, Loss: 0.0029815847519785166\n",
      "Epoch: 45, Loss: 0.002547223586589098\n",
      "Epoch: 41, Loss: 0.005071624647825956\n",
      "Epoch: 42, Loss: 0.0007323073223233223\n",
      "Epoch: 43, Loss: 0.024253185838460922\n",
      "Epoch: 44, Loss: 0.0029815847519785166\n",
      "Epoch: 45, Loss: 0.002547223586589098\n",
      "Epoch: 46, Loss: 0.07515605539083481\n",
      "Epoch: 47, Loss: 0.07906896620988846\n",
      "Epoch: 48, Loss: 0.012800740078091621\n",
      "Epoch: 49, Loss: 0.10844186693429947\n",
      "Epoch: 50, Loss: 0.039288364350795746\n",
      "Epoch: 46, Loss: 0.07515605539083481\n",
      "Epoch: 47, Loss: 0.07906896620988846\n",
      "Epoch: 48, Loss: 0.012800740078091621\n",
      "Epoch: 49, Loss: 0.10844186693429947\n",
      "Epoch: 50, Loss: 0.039288364350795746\n"
     ]
    }
   ],
   "source": [
    "# Training loop for specified number of epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        # Forward pass: compute predictions\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        # Compute loss between predictions and true labels\n",
    "        loss = loss_function(y_pred, batch_labels.view(-1, 1))\n",
    "\n",
    "        # Zero gradients before backward pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for current epoch\n",
    "    print(f'Epoch: {epoch + 1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzJuqvFHdSCV"
   },
   "source": [
    "## **15. Model Evaluation**\n",
    "Evaluate the trained model on the test set using accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Z5EjQbXORCqd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation using test_loader\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "accuracy_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_loader:\n",
    "        # Forward pass\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "        # Convert probabilities to binary predictions (threshold = 0.8)\n",
    "        y_pred = (y_pred > 0.8).float()\n",
    "\n",
    "        # Calculate accuracy for the current batch\n",
    "        batch_accuracy = (\n",
    "            y_pred.view(-1) == batch_labels).float().mean().item()\n",
    "\n",
    "        accuracy_list.append(batch_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Accuracy: {overall_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
